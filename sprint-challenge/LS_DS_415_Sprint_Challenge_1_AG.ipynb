{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Autograded Notebook (Canvas & CodeGrade)\n",
    "\n",
    "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
    "Instructions\n",
    "\n",
    "- **Download** this notebook as you would any other ipynb file \n",
    "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
    "- **Delete** `raise NotImplementedError()`\n",
    "\n",
    "- **Write** your code in the `# YOUR CODE HERE` space\n",
    "\n",
    "\n",
    "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
    "\n",
    "- **Save** your notebook when you are finished\n",
    "- **Download** as a ipynb file (if working in Colab)\n",
    "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "Successfully complete all these objectives to earn full credit. \n",
    "\n",
    "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
    "\n",
    "Each unit test that you pass is 1 point. \n",
    "\n",
    "There are 5 total possible points in this sprint challenge. \n",
    "\n",
    "\n",
    "There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
    "\n",
    "____\n",
    "\n",
    "# Before you submit your notebook you must first\n",
    "\n",
    "1) Restart your notebook's Kernal\n",
    "\n",
    "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
    "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
    "\n",
    "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
     "grade": false,
     "grade_id": "cell-395851cd95d17235",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load reviews from URL\n",
    "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
    "\n",
    "# Import data into a DataFrame named df\n",
    "data = pd.read_json(data_url, lines=True)\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "356579363f311da83f4ef7abaf3c9212",
     "grade": true,
     "grade_id": "cell-cb5006475e42b8f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
    "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 12.0 MB 12.6 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: spacy>=2.2.2 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.25.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.20.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (52.0.0.post20210125)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.26.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/anastasialysenko/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.59.0)\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
    "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
    "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4837ed2a1cc13057ba40203859d46ff6",
     "grade": false,
     "grade_id": "cell-3d570d5a1cd6cb64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \"\"\" Function that tokenizes text\n",
    "    Parameters\n",
    "    ------\n",
    "    doc: str\n",
    "    ------\n",
    "    Returns\n",
    "    ------\n",
    "    list of tokens\n",
    "    \"\"\"\n",
    "    doc_tokens = []\n",
    "    for token in nlp(doc):\n",
    "        if (token.is_digit == False) and (token.is_digit == False) \\\n",
    "            and (token.is_punct == False) and (token.is_space == False) \\\n",
    "            and (token.is_stop == False) and (token.pos_ != 'PRON'):\n",
    "                doc_tokens.append(token.text.lower())\n",
    "    return doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2181ca9d36070260b1f75dcfd9e58965",
     "grade": true,
     "grade_id": "cell-02da164f6fbe730a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Testing'''\n",
    "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4274    We went to Prosecco on Friday night for dinner...\n",
       "2602    Great food. I'm trying to promote for you but ...\n",
       "2526    This has become a must do for my girlfriend an...\n",
       "481     I have been taking my dogs here for years and ...\n",
       "4150    This place is great if you like ordering food ...\n",
       "7609    I dropped in for lunch, and sadly I wasn't sup...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f570a35b1d17ce543ee41f516a0828c",
     "grade": false,
     "grade_id": "cell-0e96491cb529202c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a vector representation of the reviews \n",
    "# Name that doc-term matrix \"dtm\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tokenize text\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(lambda x: ' '.join(tokenize(x)))\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                       ngram_range=(1, 2),\n",
    "                       min_df=2,\n",
    "                       max_df=.35)\n",
    "\n",
    "dtm = tfidf.fit_transform(df['text_cleaned'])\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
     "grade": false,
     "grade_id": "cell-3d5bc610a8ec6b24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit a NearestNeighbors model named \"nn\"\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
     "grade": true,
     "grade_id": "cell-c43704dcff67e99b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Testing.'''\n",
    "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
    "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
     "grade": false,
     "grade_id": "cell-496203e8746296ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most similar reviews are:\n",
      "------------------\n",
      "旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\n",
      "質問にも丁寧に答えてくれましたし、日本人の方も日本語が話せる方も居て、とても綺麗で居心地のいいお店でした。 \n",
      "ネイルはちはるさんと言う綺麗な方が丁寧にしてくれとても気に入りました。\n",
      "予定になかったまつ毛エクステもお願いし、日本ではまだあまりないブラウンカラーのエクステをしてもらい、とても気に入りました。\n",
      "また是非マッサージなどで伺いたいと思います。\n",
      "------------------\n",
      "------------------\n",
      "天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用心製作，包含擺盤精緻、佐料衛生，夏日想開胃，這是一個不錯的選擇，服務人員也很敬業，以後會常常來\n",
      "------------------\n",
      "------------------\n",
      "Honestly one of the best BBQ places I've ever been. Not only was the food absolutely amazing, but the service was superb! I highly recommend anyone visiting to eat here.\n",
      "------------------\n",
      "------------------\n",
      "Definetly recommend this nail salon ! Gave me exactly what I asked for. I'd give 5 stars but I was rushed once I walked in and I wasn't able to tip because I only had card. There was no wait lots of colors to choose from and the staff was beyond friendly. I would most certainly come back !\n",
      "------------------\n",
      "------------------\n",
      "Gino (aka jean machine) is up in this piece. Rolling silverware has never been more lit. He always hooks it up. Unfortunately he's not going to be there at 2 am when I truly need him. The kids say he's the old, cool dude at The Hop. Up in this hop. I agree completely. Stay lit jean machine\n",
      "------------------\n",
      "------------------\n",
      "Beautiful backyard and cool crowd. I liked my coffee and I would recommend this place for a date, or a small gathering. The only issue is the size of this place. It's very tiny. I don't recommend this place for studying cause the tiny IKEA garden chairs are not that comfortable for long sittings.\n",
      "------------------\n",
      "------------------\n",
      "I haven't been to many aquariums so I don't have a lot to compare to, but I enjoyed Odysea. We took our daughter here for her 4th Birthday celebration in lieu of a party this year. While it on the pricy side ($102 for a family of 4, one of which was free), everyone had a great time. The volunteer staff was very polite and knowledgable (we only saw them in the lower portion by the octopus). \n",
      "We went on a Monday (during the school year) so it was pretty empty which was awesome. One of the volunteers said it's not a place you want to be at during the weekend! One thing I wouldn't recommend doing is buy the photos that are taken at the entrance. They are extremely overpriced & not the greatest quality. Again, fun for a bday celebration but I wouldn't do it again. \n",
      "All-in-all, I would recommend visiting. Unless you buy a yearly membership it's not affordable (for us anyways) to go more than 1 or 2 a year though.\n",
      "------------------\n",
      "------------------\n",
      "Oh Hop In Brew, how delicious your beers are...\n",
      "\n",
      "If you live in downtown Calgary, you've probably visited the Hop In Brew many times. It's a great little house that offers you a wide selection of different delicious beers to try. I really enjoy this place because of the vibe that's always present there. There's always a diverse crowd with good music playing. I don't think you could have a bad night there. I honestly didn't even know they had food until I saw some posted here on Yelp. I'll post an update when I get to try. Oh and the bartenders are always super nice and very helpful in selecting which beer you should try based on your tastes.\n",
      "\n",
      "I'll be back soon Hop In Brew.\n",
      "------------------\n",
      "------------------\n",
      "Went to try the Vegan special sausage sandwhich. Love the vibe and very friendly staff here. It is indeed a very cool and interesting place to dine in with a few friends. \n",
      "Loved it and will definetly visit again.\n",
      "------------------\n",
      "------------------\n",
      "This place is great, so cheap, and finally some really good Chinese food in the city. I am rating 5/5 for the price, it's very cheap, really cheap, food is quite good, and there is nothing to complain about!\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a fake review and find the 10 most similar reviews\n",
    "\n",
    "fake_review = 'Lovely cheap tiny place. Would definetly recommend visiting. Hop in for lunch.'\n",
    "fake_review = tfidf.transform([' '.join(tokenize(fake_review))])\n",
    "\n",
    "most_similar_revs = nn.kneighbors(fake_review.todense())[1][0]\n",
    "\n",
    "print('Ten most similar reviews are:')\n",
    "for rev_num in most_similar_revs:\n",
    "    print('------------------')\n",
    "    print(df['text'][rev_num])\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
    "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
    "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
    "\n",
    "\n",
    "\n",
    "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
    "    - Include 2 possible values for each parameter\n",
    "    - **Use `n_jobs` = 1** \n",
    "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
    "    \n",
    "    \n",
    "3. Train the entire pipeline with a GridSearch\n",
    "    - Name your GridSearch object as `gs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
     "grade": false,
     "grade_id": "cell-e2beb0252d274bba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=2,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='hinge', max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'clf__C': (1.0, 2.0), 'vect__max_df': (0.35, 0.75)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Name the gridsearch instance \"gs\"\n",
    "\n",
    "# vectorizer\n",
    "vect = TfidfVectorizer(stop_words='english',\n",
    "                       ngram_range=(1, 2),\n",
    "                       min_df=2)\n",
    "\n",
    "# classifier\n",
    "clf = LinearSVC(penalty='l2', \n",
    "                loss='hinge')\n",
    "\n",
    "# pipeline\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "\n",
    "# parameters\n",
    "params = {\n",
    "    'vect__max_df':(.35, .75),\n",
    "    'clf__C':(1., 2.)\n",
    "}\n",
    "\n",
    "# gridsearch\n",
    "gs = GridSearchCV(pipe, params, cv=5, n_jobs=1)\n",
    "gs.fit(df['text_cleaned'], df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9e2378efb868f104a4eb39e4f25563c",
     "grade": true,
     "grade_id": "cell-d07134c6fe5d056e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\n",
    "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Set num_topics to `5`\n",
    "    - Name your LDA model `lda`\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "When you instantiate your LDA model, it should look like this: \n",
    "\n",
    "```python\n",
    "lda = LdaModel(corpus=corpus,\n",
    "               id2word=id2word,\n",
    "               random_state=723812,\n",
    "               num_topics = num_topics,\n",
    "               passes=1\n",
    "              )\n",
    "\n",
    "```\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note about  pyLDAvis\n",
    "\n",
    "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
    "\n",
    "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
    "\n",
    "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Estimate a LDA topic model of the review tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9514841e71735eaa255bccc53b257896",
     "grade": false,
     "grade_id": "cell-66331a185ff52f15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
    "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\n",
    "# don't change this value \n",
    "num_topics = 5\n",
    "\n",
    "# use tokenize function you created earlier to create tokens\n",
    "df['text_tokenized'] = df['text'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# create a id2word object (hint: use corpora.Dictionary)\n",
    "id2word = corpora.Dictionary(df['text_tokenized'])\n",
    "\n",
    "# create a corpus object (hint: id2word.doc2bow)\n",
    "corpus = [id2word.doc2bow(doc) for doc in df['text_tokenized']]\n",
    "\n",
    "# instantiate an lda model\n",
    "lda = LdaModel(corpus=corpus,\n",
    "               id2word=id2word,\n",
    "               random_state=723812,\n",
    "               num_topics = num_topics,\n",
    "               passes=1\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
     "grade": true,
     "grade_id": "cell-5a3c181311134fa9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "189591ed7b9e6e6146d59761fb418268",
     "grade": false,
     "grade_id": "cell-9b043e992fbd218c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el629411403033912158089221884046\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el629411403033912158089221884046_data = {\"mdsDat\": {\"x\": [-0.13037310786516282, 0.07390503187984368, 0.00018343984047576202, -0.00887592385718551, 0.06516056000202891], \"y\": [0.009338247474072393, 0.07227755705438423, -0.019588173164394068, 0.0010652905478388142, -0.06309292191190136], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [41.98399357818165, 17.462666083112076, 16.987883952393393, 12.76476642489873, 10.800689961414154]}, \"tinfo\": {\"Term\": [\"time\", \"food\", \"great\", \"pizza\", \"$\", \"room\", \"told\", \"staff\", \"said\", \"like\", \"order\", \"got\", \"came\", \"store\", \"minutes\", \"car\", \"hair\", \"work\", \"know\", \"asked\", \"called\", \"want\", \"nail\", \"professional\", \"new\", \"people\", \"nails\", \"service\", \"went\", \"going\", \"yuk\", \"cajun\", \"tamale\", \"burgers\", \"guacamole\", \"margarita\", \"pico\", \"milkshakes\", \"yuck\", \"chorizo\", \"brulee\", \"ravioli\", \"ale\", \"bouchon\", \"tartar\", \"smokey\", \"skinny\", \"appetite\", \"gooey\", \"yellowtail\", \"bleu\", \"carolina\", \"gyros\", \"dente\", \"pastor\", \"soo\", \"doughnuts\", \"jambalaya\", \"butternut\", \"promotion\", \"tacos\", \"burger\", \"ambience\", \"jalape\\u00f1o\", \"fries\", \"sauces\", \"salsa\", \"yummy\", \"queso\", \"toasted\", \"creme\", \"curry\", \"sushi\", \"delicious\", \"tasty\", \"mexican\", \"flavorful\", \"sauce\", \"chips\", \"fresh\", \"menu\", \"bbq\", \"fish\", \"beef\", \"good\", \"cheese\", \"soup\", \"food\", \"fried\", \"salad\", \"lunch\", \"ordered\", \"meal\", \"chicken\", \"eat\", \"spicy\", \"place\", \"taste\", \"cream\", \"great\", \"meat\", \"restaurant\", \"try\", \"dinner\", \"little\", \"definitely\", \"service\", \"nice\", \"best\", \"like\", \"amazing\", \"pretty\", \"friendly\", \"order\", \"love\", \"time\", \"$\", \"come\", \"got\", \"brewery\", \"jennifer\", \"josh\", \"tint\", \"reach\", \"blind\", \"easter\", \"plumber\", \"directions\", \"professionally\", \"manicures\", \"plumbers\", \"referred\", \"wi\", \"rep\", \"smog\", \"macy\", \"lane\", \"nite\", \"friendlier\", \"curls\", \"arrogant\", \"brakes\", \"rick\", \"bumper\", \"dentistry\", \"houses\", \"mahi\", \"medicine\", \"rugs\", \"cats\", \"sessions\", \"wheels\", \"routine\", \"dr.\", \"bike\", \"fi\", \"plumbing\", \"patients\", \"professional\", \"tony\", \"donuts\", \"maintenance\", \"barber\", \"doctor\", \"patient\", \"repair\", \"mike\", \"massage\", \"pain\", \"grateful\", \"job\", \"team\", \"pressure\", \"shop\", \"staff\", \"thank\", \"results\", \"easy\", \"knowledgeable\", \"work\", \"care\", \"office\", \"hotel\", \"great\", \"helpful\", \"years\", \"recommend\", \"new\", \"thanks\", \"highly\", \"friendly\", \"time\", \"looking\", \"clean\", \"store\", \"going\", \"experience\", \"place\", \"love\", \"needed\", \"service\", \"feel\", \"took\", \"like\", \"nice\", \"people\", \"customer\", \"good\", \"amazing\", \"day\", \"best\", \"location\", \"come\", \"keg\", \"attached\", \"neighbor\", \"ears\", \"repeated\", \"mercedes\", \"ihop\", \"hakka\", \"screwed\", \"sisters\", \"ethiopian\", \"spell\", \"mold\", \"scrumptious\", \"tai\", \"capacity\", \"death\", \"kia\", \"pee\", \"ramsay\", \"gordon\", \"trusted\", \"howard\", \"pinch\", \"grubhub\", \"michelle\", \"skill\", \"peter\", \"queue\", \"zen\", \"male\", \"label\", \"values\", \"dentists\", \"jeremy\", \"stylist\", \"convention\", \"mins\", \"hair\", \"lead\", \"alex\", \"kevin\", \"waited\", \"direct\", \"told\", \"car\", \"minutes\", \"finally\", \"involved\", \"said\", \"root\", \"waiting\", \"awful\", \"asked\", \"order\", \"time\", \"terrible\", \"got\", \"lady\", \"customer\", \"service\", \"came\", \"later\", \"cut\", \"window\", \"bad\", \"customers\", \"went\", \"rude\", \"left\", \"food\", \"wanted\", \"took\", \"know\", \"times\", \"like\", \"experience\", \"$\", \"people\", \"day\", \"good\", \"table\", \"place\", \"ordered\", \"come\", \"restaurant\", \"chicken\", \"pistachio\", \"adds\", \"freezer\", \"curly\", \"ikea\", \"stunning\", \"bouncers\", \"heartbeat\", \"unorganized\", \"cesar\", \"humor\", \"circle\", \"oasis\", \"l\", \"tricks\", \"refrigerator\", \"baba\", \"brows\", \"dissatisfied\", \"computers\", \"gabi\", \"rubber\", \"boba\", \"contractor\", \"hahaha\", \"solved\", \"msg\", \"upcoming\", \"mandalay\", \"laughed\", \"audience\", \"chilled\", \"bourbon\", \"gifts\", \"dress\", \"cupcakes\", \"roti\", \"eyebrow\", \"frosting\", \"cousin\", \"suite\", \"room\", \"dance\", \"gym\", \"rooms\", \"view\", \"floor\", \"casino\", \"like\", \"night\", \"$\", \"vegas\", \"club\", \"know\", \"people\", \"came\", \"strip\", \"hotel\", \"want\", \"check\", \"pool\", \"buffet\", \"got\", \"said\", \"stay\", \"better\", \"time\", \"way\", \"place\", \"fun\", \"day\", \"service\", \"amazing\", \"different\", \"stars\", \"great\", \"come\", \"best\", \"try\", \"little\", \"bit\", \"food\", \"good\", \"right\", \"staff\", \"greatest\", \"tart\", \"layout\", \"johnny\", \"updating\", \"dans\", \"\\u00e0\", \"une\", \"mais\", \"tan\", \"staffs\", \"hoagie\", \"tr\\u00e8s\", \"et\", \"des\", \"sur\", \"lil\", \"en\", \"horribly\", \"jalape\\u00f1os\", \"barbeque\", \"a.m.\", \"comme\", \"je\", \"screens\", \"vous\", \"mule\", \"nailed\", \"est\", \"acrylic\", \"pedicure\", \"les\", \"polish\", \"nail\", \"pedicures\", \"nails\", \"le\", \"gel\", \"un\", \"pas\", \"answers\", \"manicure\", \"de\", \"feet\", \"dog\", \"la\", \"pour\", \"spray\", \"dogs\", \"phone\", \"money\", \"gift\", \"store\", \"pizza\", \"salon\", \"called\", \"$\", \"review\", \"place\", \"park\", \"want\", \"company\", \"going\", \"day\", \"time\", \"business\", \"went\", \"love\", \"said\", \"got\", \"like\", \"told\", \"know\", \"right\", \"service\", \"good\", \"great\", \"new\", \"work\", \"people\", \"best\"], \"Freq\": [3402.0, 5081.0, 4378.0, 813.0, 2169.0, 897.0, 931.0, 1597.0, 1147.0, 3441.0, 1566.0, 2092.0, 1476.0, 667.0, 881.0, 592.0, 388.0, 919.0, 1158.0, 794.0, 611.0, 989.0, 175.0, 347.0, 1105.0, 1439.0, 177.0, 3642.0, 1455.0, 1143.0, 59.58384793633391, 35.78814633971574, 28.054791117155048, 183.1516386794727, 103.15674637408813, 68.08724339604935, 21.0370067293703, 21.428685959135052, 18.719432185818356, 40.251712525514904, 29.479917724427654, 48.052843555417994, 30.16261252136278, 17.50960108372294, 17.459548438764358, 24.42948265159504, 18.68295479192722, 19.67911232852684, 18.28978213682741, 32.80611421899784, 15.504007671911591, 15.80640783755605, 28.07919997990135, 18.290263696332087, 27.462543830868434, 34.48323825615077, 14.385346419721706, 13.992557830484522, 18.758242041236752, 17.576044477957307, 336.3307774395827, 546.8095767333481, 82.54002587254266, 35.63402957210214, 585.8733055956454, 110.47226748163921, 209.20552051116405, 227.91780020887919, 44.54692196325539, 54.6401639700183, 52.93383615554182, 140.6904631963824, 518.9662906867413, 1142.178597621035, 480.48492384629714, 220.79561194786865, 170.35342966529058, 737.9004240290436, 245.9460645139623, 817.9446658434229, 1063.0764398241504, 222.0761702557431, 357.3642094020778, 419.0862406262364, 3649.6041765944738, 710.5177333997208, 432.5621072658477, 3686.709335001133, 437.6333838204334, 562.1871957157513, 632.861364953518, 1223.5604758391805, 604.0190349676365, 1093.4196755663536, 688.349073651769, 326.0227096697361, 2931.6803770829115, 516.7407412782275, 461.5952648071044, 2622.1559078608443, 480.61080290994937, 932.9306289689923, 1009.5645550018279, 525.0640748441325, 954.1960130776914, 916.9319341257832, 1750.1703153323895, 1028.0836672967587, 1040.2999397158894, 1540.9735869751266, 843.2984960555411, 710.4769396964043, 841.6250560963167, 855.4746838160248, 848.3861279071691, 1067.251767534401, 829.4260843671209, 717.4495431669802, 773.4327322802527, 25.960121491921278, 26.67764078449132, 21.58649888172121, 16.734775840975896, 26.928323033617676, 15.353103788503674, 14.641002374368151, 23.20651211887936, 19.898168028449344, 15.030442032191967, 13.850303015023167, 11.92299567582912, 47.4257460188932, 23.01910439829691, 18.688140361436425, 13.78119035074726, 10.972502695284867, 18.255326955573796, 10.12406342396868, 13.440706981612738, 10.294440279011738, 11.797693873586173, 13.083688576820508, 9.055427146697532, 9.421076800780767, 10.216398375986815, 17.54831901073087, 9.122731598654005, 10.30123996835567, 9.993852475809224, 35.08434979638913, 25.36214942579268, 20.738923472627626, 24.55611559037958, 162.72043064706466, 48.907976303602155, 21.54637782685912, 37.51946312141896, 35.24322180070795, 267.3638390715745, 43.351766861798815, 93.63252960232319, 52.16182457348014, 36.954929773357954, 83.94977197656482, 99.9587241424666, 90.24042896979823, 34.77646831719476, 100.35704941584042, 69.2945939057529, 30.41171780549712, 279.92297526943025, 88.23954219651438, 42.24040995565147, 217.65733949572362, 684.1935082061482, 200.40927220523955, 69.91860472081036, 146.5249137328204, 109.34067584902742, 390.418498510782, 255.1246685934495, 169.46014853735173, 209.20368946404844, 1128.5109537701555, 195.24790309617944, 257.1577308552635, 411.1195373855108, 389.8622056464547, 133.4555704299497, 235.55273082187296, 427.49783427477513, 752.2642194711188, 256.1944912988514, 257.5940316594017, 244.54114474754823, 328.6032999153372, 347.8111916462025, 672.6670351210747, 376.507205348256, 185.4082789044341, 537.8974503770802, 224.2534031196218, 248.24920022314026, 470.31205518841745, 334.6325912765661, 291.4544226280131, 234.57270063472166, 372.4430469406396, 266.91904464626606, 255.27242221172264, 278.2953064680519, 237.43904218457973, 246.61830699150283, 27.636360671382484, 33.46602059633864, 20.29777901487651, 15.442129466268717, 16.434036367297434, 16.79668156889606, 15.522830587412695, 12.627371093568682, 21.050449152311888, 11.925614781706834, 14.593427038827858, 12.801155421397961, 11.800336718118754, 11.040690151718408, 11.328908953838088, 11.648366282639165, 19.753554198731578, 11.409391314443925, 9.64687830267784, 10.060387122513367, 20.011041329187194, 12.03846652948085, 9.288416448091366, 10.106706976785935, 8.602129375266736, 10.836183715527277, 12.802359202064125, 8.84489619278975, 8.909131100640721, 8.499918594324745, 19.244698060411633, 14.120324501247, 12.696141995200938, 14.51017371140557, 14.961711002494297, 55.90008831294395, 14.661295403813684, 91.37677885478195, 268.22604941056426, 20.778100650216018, 18.401415634500445, 19.20862767528671, 183.85591955574927, 23.965785969807293, 493.88239787868173, 316.07999124445826, 427.76635501069967, 211.1288508347516, 22.659866845175483, 488.4972641488788, 39.17748766923436, 224.27196483964696, 79.8470369682156, 347.95573987896535, 531.451295080694, 954.886698291223, 108.9964746259598, 593.8898657153792, 103.03265591589727, 287.2748659379688, 864.9991551103838, 435.4370032099756, 151.24487730392931, 152.60133608993553, 84.10135324609594, 278.388760280527, 134.39983770197637, 412.7842562432983, 137.98550223402071, 209.83235395362595, 907.3250300995873, 215.10299582932518, 256.88863987647085, 302.7772083458012, 248.36613096919794, 559.5350031213827, 302.0470502217771, 379.81836766283504, 303.33071315133185, 255.5796724492584, 469.06340994774195, 207.21874171180167, 400.78227371176314, 257.5855942152086, 242.73055348101985, 230.3376231549843, 226.94877138250007, 21.451358001663724, 26.11304854789621, 20.158241834534884, 17.975181882168076, 18.30251242697251, 16.352324299131453, 16.75299778258361, 15.633841594904474, 15.942043260790548, 12.338242775059111, 12.493646053270348, 12.894849497210947, 18.604767756530652, 17.646283013613104, 15.211317571042475, 10.914529073530518, 10.280312781679953, 15.970398841636472, 12.395582703432158, 10.598975328664975, 11.898124961218997, 10.699631891944062, 55.67379008462967, 10.287292990079399, 8.677247875529417, 8.479174693855661, 15.776686606015902, 14.313816010296472, 26.200236928863976, 19.698356494475934, 18.751679989831334, 12.859968216452275, 18.98595486229428, 23.259529293936307, 42.56664919460679, 25.87949046944983, 18.603531780883035, 15.715482457267818, 21.25393424614784, 17.51598279602975, 45.713277917627714, 355.87472691109724, 39.836163411871794, 60.10730659168309, 89.77718226303446, 85.43001877550093, 86.33069291327264, 69.0363970807482, 639.6797138096155, 255.82939670518783, 421.3500482021016, 234.24321136583612, 63.16174015447766, 242.2271397797202, 276.5840147544605, 273.39045488635475, 103.22753634422891, 121.99512233461839, 200.1144888725601, 150.9135032545035, 79.54070978908217, 80.7342454821949, 296.64913085408085, 200.57142619512234, 99.0566071750548, 192.41574028164897, 337.8811634841233, 185.7776168863021, 363.85553664224255, 112.17951394048973, 174.19457050198528, 292.2132429984012, 175.665597099798, 127.57292234240795, 121.25403995939283, 252.75449049925336, 166.40279318587616, 171.86244254483938, 157.7750220622523, 150.68591127362362, 127.6915903763891, 187.96523629534573, 180.06268106886642, 124.41021875006307, 125.08382547801463, 28.99048465253468, 29.98615595463105, 27.537686367406526, 17.67934540720787, 13.97447204309072, 14.264150978625416, 45.87100624310694, 25.683997157718455, 19.999841328015858, 35.31907202784393, 16.76317160813939, 12.872690065955275, 20.849036820120187, 56.786945660287465, 28.029926685682657, 11.42096570166479, 13.373698077637878, 36.31642147375458, 15.36832248662684, 14.01768120619271, 11.625627044260774, 10.863535424429482, 10.604936350759447, 17.650515990920233, 18.078533867028664, 21.051996458005952, 10.812719892082352, 9.811981477300392, 26.0861041285206, 18.31600033709547, 97.78423617205631, 37.81372097111709, 66.72904180541961, 153.9377129436108, 26.134332522487387, 150.8800984326135, 60.8314729003215, 82.83626134986504, 45.4911620388844, 20.532237013268187, 27.691762466412502, 39.26447325844269, 93.69267834360407, 59.82959064204294, 138.54445238867146, 107.66869780553803, 36.43430803659183, 25.833482682160017, 68.95615145505566, 136.7123206387425, 166.38473666287857, 47.850647442333845, 189.35173994227915, 210.27365745381172, 85.38724667542505, 163.81634971559225, 320.3084042723916, 132.2011903753341, 466.73309168041567, 73.35246871250402, 192.30412997193642, 104.2563018033705, 189.2073344510145, 181.92312017636547, 290.5556440730315, 113.43886154583785, 193.15430438126575, 186.28201361070924, 156.08469122611518, 195.94620062787368, 231.08949925163466, 141.38519721282972, 151.83443936305213, 148.78539797806252, 197.3524365023869, 195.51767809257473, 180.25482633665197, 134.7959168842271, 126.87006797032852, 131.4043274332641, 113.49629540985832], \"Total\": [3402.0, 5081.0, 4378.0, 813.0, 2169.0, 897.0, 931.0, 1597.0, 1147.0, 3441.0, 1566.0, 2092.0, 1476.0, 667.0, 881.0, 592.0, 388.0, 919.0, 1158.0, 794.0, 611.0, 989.0, 175.0, 347.0, 1105.0, 1439.0, 177.0, 3642.0, 1455.0, 1143.0, 60.416500254417166, 36.72039312689527, 28.831721063912262, 188.88430826556552, 106.76072647247095, 70.68941389824013, 21.855786220470076, 22.294292989225973, 19.490453314363247, 41.9592746134166, 30.732596322867128, 50.1325608516066, 31.484920614136254, 18.282576260926525, 18.26283092452711, 25.570704196363163, 19.56302352054153, 20.60943177797197, 19.161957893808726, 34.374427914287786, 16.260209221966768, 16.590093895231533, 29.482884626103186, 19.2145181112957, 28.851071148331364, 36.31156391730598, 15.158798645802433, 14.745098160448897, 19.771431382509395, 18.542400400521867, 356.2344804540836, 588.4313836149212, 87.46267855388757, 37.66567589627895, 644.3860145645394, 118.4333331234931, 227.65373460919866, 249.45588061233835, 47.27547155437649, 58.240139684974125, 56.4121598582183, 153.21987071784142, 585.5555933897446, 1321.01362203666, 541.0538618650189, 243.7449616070593, 187.31567974826686, 851.6883313129176, 276.5298862901173, 969.0916288457489, 1304.682216701206, 252.61893618938967, 417.67980929133336, 496.2695651407092, 4866.690992644297, 870.0668231212712, 516.2556230762884, 5081.241784046203, 527.1396556028673, 691.3381429093535, 788.5023465214634, 1627.9287999693329, 758.0409722918814, 1468.7429867423427, 884.5335029823826, 391.4538745759461, 4835.718314238407, 661.9818456615372, 582.4217484735182, 4378.972714714239, 610.4529188230701, 1376.825053652355, 1514.634008569262, 692.5526167455674, 1464.5805729498522, 1452.4883727664185, 3642.6326003206414, 1761.0102446924686, 1822.2586779161243, 3441.5898583461767, 1413.5352795129968, 1109.8196726397264, 1449.7471385074039, 1566.4522741319659, 1671.4030997745024, 3402.8394928538974, 2169.6777843411764, 1472.8159899674806, 2092.959183028538, 26.780503394236575, 27.826948872465195, 22.638982021378684, 17.597969657025555, 28.365889360085163, 16.17705811294495, 15.433360508917911, 24.51091242082584, 21.111333067344628, 15.977318946409365, 14.767923065539517, 12.716515892973543, 50.93263459917059, 24.752533777693518, 20.167489263108198, 14.875256675854393, 11.844469543503507, 19.70804487710861, 10.930195973823487, 14.511608357647283, 11.141219768413496, 12.771756598945514, 14.184387973216548, 9.82836110745122, 10.225751939656982, 11.094136068903854, 19.105832595945973, 9.957360130462435, 11.257532270145722, 10.923388125191826, 38.48581265875501, 27.857589638554888, 22.76692201959719, 27.041851670010942, 186.49487192469456, 55.01480488581719, 23.795546946022732, 42.39024475995317, 39.84662095960612, 347.42185284133285, 50.692036340963426, 115.41900943112562, 62.871990666441995, 43.24450301260387, 108.46856892743821, 134.27054957185362, 120.80763642037857, 41.19143245592461, 140.80130807432167, 93.41482079099751, 35.70097552309171, 493.1709305780738, 125.40079649215112, 52.592244042657654, 392.9627290419734, 1597.8937022367095, 367.6206617035592, 98.91813959899947, 256.8476145472897, 178.97988611463683, 919.972737425207, 530.5621211421711, 314.31480422599145, 419.78530332899516, 4378.972714714239, 412.11796220072534, 608.3937311152039, 1168.3685810361617, 1105.0238437684727, 249.6205059146881, 562.0030069930173, 1449.7471385074039, 3402.8394928538974, 691.1214990338067, 717.5665534801628, 667.12680103413, 1143.330302556904, 1263.3704924890517, 4835.718314238407, 1671.4030997745024, 459.23036966506487, 3642.6326003206414, 670.5712415071745, 869.645780899754, 3441.5898583461767, 1761.0102446924686, 1439.9171482691263, 802.850758811576, 4866.690992644297, 1413.5352795129968, 1181.7334092588915, 1822.2586779161243, 883.2030835255263, 1472.8159899674806, 28.444574085328203, 34.47256751035201, 21.112999779942594, 16.252986216108106, 17.29984341205288, 17.724962380998157, 16.385003704739734, 13.415415083794192, 22.367851178590566, 12.718266472530841, 15.579602993126993, 13.728980862358128, 12.690552129535599, 11.901030148475273, 12.236991492268038, 12.589483978088667, 21.37468556027062, 12.369942825814174, 10.464123389280482, 10.914577381897189, 21.710464221188982, 13.090008716226867, 10.10424231283974, 10.996426821231298, 9.374479878205982, 11.818870669236027, 13.96340899668035, 9.654881251351883, 9.728671037546144, 9.288835733287133, 21.064205023804963, 15.474283095028422, 13.931104888707571, 15.985330879285964, 16.58958638890154, 67.41760511164898, 16.313381837380167, 116.78473634013358, 388.3131730907818, 24.021897444716423, 21.11832299980061, 22.265838260010828, 295.6592188160261, 28.673631343350074, 931.3312775642937, 592.2554706282582, 881.9485683022891, 391.8328233902881, 27.49579771306262, 1147.250335688946, 53.57604683801858, 457.8870452539792, 128.6037897209751, 794.2712593489215, 1566.4522741319659, 3402.8394928538974, 209.90993063834196, 2092.959183028538, 203.55433861433002, 802.850758811576, 3642.6326003206414, 1476.698002282638, 351.45602893783865, 357.3353841892773, 158.01146458272763, 816.7174574159268, 305.2907573769771, 1455.5485228455148, 320.16088508757025, 591.538853478715, 5081.241784046203, 627.2124535456339, 869.645780899754, 1158.1214383213912, 868.1656441632672, 3441.5898583461767, 1263.3704924890517, 2169.6777843411764, 1439.9171482691263, 1181.7334092588915, 4866.690992644297, 795.5572232930946, 4835.718314238407, 1627.9287999693329, 1472.8159899674806, 1376.825053652355, 1468.7429867423427, 22.251456601392913, 27.089794919307863, 20.961733778757065, 18.812762300240976, 19.18478144652304, 17.15434002136161, 17.617592599191365, 16.470817113164017, 16.819907429640594, 13.133219653763007, 13.301940571549444, 13.736429024148883, 19.876256384843053, 18.87995827037878, 16.278207331617523, 11.7355275848194, 11.096997755184095, 17.295293793296718, 13.431649650558336, 11.492917157480953, 12.943649858306443, 11.663966510674179, 60.75124093851076, 11.228879489375393, 9.478936283610947, 9.285922184653568, 17.279002999900378, 15.681133060256537, 28.75442999654015, 21.642553929517202, 20.708730767829575, 14.159224190872305, 21.08070853920023, 26.79396435442232, 52.098081443354474, 30.680612380295788, 21.404456574455068, 17.716788207847742, 25.07611147005027, 20.185435173442226, 63.88851162344779, 897.8522112414371, 56.94471267281983, 106.01253285522674, 185.45265132449413, 176.722140786315, 191.34434046986416, 140.15909557952554, 3441.5898583461767, 955.1706554241196, 2169.6777843411764, 908.6827571242292, 138.63665630350448, 1158.1214383213912, 1439.9171482691263, 1476.698002282638, 316.04013791662294, 419.78530332899516, 989.2340440772776, 640.2986601017328, 221.31177586643744, 227.22572474621703, 2092.959183028538, 1147.250335688946, 333.41393508902075, 1143.4157439481783, 3402.8394928538974, 1115.2123793679843, 4835.718314238407, 463.0823830348536, 1181.7334092588915, 3642.6326003206414, 1413.5352795129968, 702.1479857836248, 625.5803322441182, 4378.972714714239, 1472.8159899674806, 1822.2586779161243, 1514.634008569262, 1464.5805729498522, 854.6447836861989, 5081.241784046203, 4866.690992644297, 1095.8942034427419, 1597.8937022367095, 29.82147901242043, 30.87036558268545, 28.376508930438362, 18.516162270962695, 14.78709538516684, 15.115162034988655, 48.60910588456257, 27.236446380929852, 21.240642178702988, 37.520021072814366, 17.89849021353399, 13.745302410242823, 22.26237118346903, 60.8156809086967, 30.031389998085235, 12.246057341972948, 14.352671483532202, 39.00150699387508, 16.531127954918087, 15.104009688924668, 12.531899843445997, 11.721328489320593, 11.447898479057333, 19.058219113405, 19.55667977696346, 22.814652346759374, 11.721713344799678, 10.639724906277634, 28.30942838929001, 19.91715576613165, 107.31397775130237, 41.12132747449403, 74.24164534105282, 175.85206210751275, 28.744104467250473, 177.11703495496988, 69.11281405822294, 95.95665550013648, 52.83613138327674, 22.826308292023796, 32.72523783214686, 49.21752410244456, 137.95655323533336, 82.63940932908051, 250.08166582360718, 182.31863207382247, 47.92204391837173, 31.07211898742819, 123.56590384435478, 333.33834806089874, 460.6861490156534, 78.23871484322056, 667.12680103413, 813.3381743812502, 203.15123249140578, 611.8748671644662, 2169.6777843411764, 465.2662469135962, 4835.718314238407, 167.43240499451406, 989.2340440772776, 346.3159744449175, 1143.330302556904, 1181.7334092588915, 3402.8394928538974, 443.8204309347411, 1455.5485228455148, 1671.4030997745024, 1147.250335688946, 2092.959183028538, 3441.5898583461767, 931.3312775642937, 1158.1214383213912, 1095.8942034427419, 3642.6326003206414, 4866.690992644297, 4378.972714714239, 1105.0238437684727, 919.972737425207, 1439.9171482691263, 1822.2586779161243], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.133700370788574, -8.643500328063965, -8.886899948120117, -7.010799884796143, -7.584799766540527, -8.000300407409668, -9.174799919128418, -9.156299591064453, -9.291500091552734, -8.525899887084961, -8.837400436401367, -8.348799705505371, -8.814499855041504, -9.35830020904541, -9.361200332641602, -9.025300025939941, -9.293499946594238, -9.241499900817871, -9.31470012664795, -8.730500221252441, -9.479999542236328, -9.460700035095215, -8.88599967956543, -9.31470012664795, -8.90820026397705, -8.6806001663208, -9.554900169372559, -9.582500457763672, -9.289400100708008, -9.354499816894531, -6.4029998779296875, -5.916999816894531, -7.807799816131592, -8.64780044555664, -5.8480000495910645, -7.516300201416016, -6.877799987792969, -6.792099952697754, -8.424500465393066, -8.22029972076416, -8.251999855041504, -7.274499893188477, -5.969200134277344, -5.1803998947143555, -6.046299934387207, -6.823800086975098, -7.083199977874756, -5.617300033569336, -6.716000080108643, -5.5142998695373535, -5.252099990844727, -6.817999839782715, -6.342299938201904, -6.183000087738037, -4.018700122833252, -5.655099868774414, -6.151299953460693, -4.008600234985352, -6.139699935913086, -5.889200210571289, -5.7708001136779785, -5.111499786376953, -5.817500114440918, -5.223999977111816, -5.686800003051758, -6.434100151062012, -4.23769998550415, -5.973499774932861, -6.086400032043457, -4.349299907684326, -6.046000003814697, -5.382699966430664, -5.303800106048584, -5.957499980926514, -5.360199928283691, -5.400000095367432, -4.753600120544434, -5.285600185394287, -5.273799896240234, -4.880899906158447, -5.483699798583984, -5.655099868774414, -5.4857001304626465, -5.469399929046631, -5.477700233459473, -5.248199939727783, -5.50029993057251, -5.645400047302246, -5.570199966430664, -8.087300300598145, -8.0600004196167, -8.27180004119873, -8.526399612426758, -8.050700187683105, -8.612500190734863, -8.65999984741211, -8.199399948120117, -8.35319995880127, -8.63379955291748, -8.715499877929688, -8.865400314331055, -7.4847002029418945, -8.207500457763672, -8.416000366210938, -8.720499992370605, -8.94849967956543, -8.439399719238281, -9.028900146484375, -8.745599746704102, -9.012200355529785, -8.875900268554688, -8.772500038146973, -9.14050006866455, -9.100899696350098, -9.019800186157227, -8.478899955749512, -9.133099555969238, -9.01159954071045, -9.041899681091309, -7.786099910736084, -8.110600471496582, -8.311800003051758, -8.142900466918945, -6.251800060272217, -7.45389986038208, -8.273599624633789, -7.718999862670898, -7.781599998474121, -5.755199909210205, -7.57450008392334, -6.804500102996826, -7.389500141143799, -7.734099864959717, -6.913599967956543, -6.739099979400635, -6.841400146484375, -7.794899940490723, -6.735099792480469, -7.105500221252441, -7.928999900817871, -5.7093000411987305, -6.863800048828125, -7.600500106811523, -5.960899829864502, -4.8155999183654785, -6.043499946594238, -7.096499919891357, -6.356599807739258, -6.649400234222412, -5.3765997886657715, -5.80210018157959, -6.21120023727417, -6.000500202178955, -4.315199851989746, -6.0696001052856445, -5.7941999435424805, -5.324999809265137, -5.3780999183654785, -6.450099945068359, -5.881899833679199, -5.285900115966797, -4.720799922943115, -5.797900199890137, -5.792500019073486, -5.8445000648498535, -5.548999786376953, -5.492199897766113, -4.832600116729736, -5.412899971008301, -6.121300220489502, -5.05620002746582, -5.931099891662598, -5.829400062561035, -5.190400123596191, -5.530799865722656, -5.669000148773193, -5.886099815368652, -5.423799991607666, -5.756899833679199, -5.801499843597412, -5.715199947357178, -5.873899936676025, -5.835999965667725, -7.997099876403809, -7.805699825286865, -8.305800437927246, -8.57919979095459, -8.516900062561035, -8.495100021362305, -8.574000358581543, -8.780400276184082, -8.269399642944336, -8.837599754333496, -8.635700225830078, -8.76669979095459, -8.848199844360352, -8.91469955444336, -8.888899803161621, -8.861100196838379, -8.332900047302246, -8.881799697875977, -9.049599647521973, -9.007699966430664, -8.319999694824219, -8.828200340270996, -9.087499618530273, -9.003100395202637, -9.164299964904785, -8.93340015411377, -8.766599655151367, -9.13640022277832, -9.129199981689453, -9.176199913024902, -8.359000205993652, -8.668700218200684, -8.774999618530273, -8.641400337219238, -8.610799789428711, -7.292699813842773, -8.631099700927734, -6.801300048828125, -5.724400043487549, -8.282400131225586, -8.403900146484375, -8.360899925231934, -6.102099895477295, -8.139699935913086, -5.113999843597412, -5.560299873352051, -5.257699966430664, -5.963799953460693, -8.195699691772461, -5.124899864196777, -7.648200035095215, -5.90339994430542, -6.936200141906738, -5.464200019836426, -5.0406999588012695, -4.454699993133545, -6.625, -4.929599761962891, -6.68120002746582, -5.655799865722656, -4.553599834442139, -5.2399001121521, -6.297399997711182, -6.28849983215332, -6.884300231933594, -5.687300205230713, -6.415500164031982, -5.293399810791016, -6.389100074768066, -5.96999979019165, -4.505799770355225, -5.945199966430664, -5.767600059509277, -5.603300094604492, -5.801400184631348, -4.989200115203857, -5.6057000160217285, -5.3765997886657715, -5.601500034332275, -5.77269983291626, -5.165500164031982, -5.982500076293945, -5.32289981842041, -5.764900207519531, -5.8242998123168945, -5.876699924468994, -5.891600131988525, -7.964700222015381, -7.76800012588501, -8.026900291442871, -8.141500473022461, -8.12339973449707, -8.236100196838379, -8.211899757385254, -8.281000137329102, -8.261500358581543, -8.517800331115723, -8.505200386047363, -8.473600387573242, -8.107000350952148, -8.159899711608887, -8.30840015411377, -8.640399932861328, -8.700200080871582, -8.259699821472168, -8.513099670410156, -8.669699668884277, -8.554100036621094, -8.660300254821777, -7.011000156402588, -8.699600219726562, -8.869799613952637, -8.892900466918945, -8.271900177001953, -8.369199752807617, -7.764699935913086, -8.04990005493164, -8.099200248718262, -8.476300239562988, -8.086799621582031, -7.883800029754639, -7.279399871826172, -7.7769999504089355, -8.107099533081055, -8.275799751281738, -7.973899841308594, -8.167400360107422, -7.208099842071533, -5.155900001525879, -7.345699787139893, -6.934299945831299, -6.533100128173828, -6.582799911499023, -6.572299957275391, -6.79580020904541, -4.569499969482422, -5.486000061035156, -4.986999988555908, -5.574100017547607, -6.884799957275391, -5.540599822998047, -5.4079999923706055, -5.419600009918213, -6.393499851226807, -6.226500034332275, -5.731599807739258, -6.013800144195557, -6.654200077056885, -6.6392998695373535, -5.337900161743164, -5.729300022125244, -6.434800148010254, -5.7708001136779785, -5.207799911499023, -5.8059000968933105, -5.133699893951416, -6.310400009155273, -5.870299816131592, -5.353000164031982, -5.8618998527526855, -6.18179988861084, -6.232600212097168, -5.498000144958496, -5.916100025177002, -5.883800029754639, -5.969299793243408, -6.0152997970581055, -6.180799961090088, -5.7941999435424805, -5.837200164794922, -6.206900119781494, -6.201499938964844, -7.496399879455566, -7.462699890136719, -7.547800064086914, -7.991000175476074, -8.226200103759766, -8.205599784851074, -7.037600040435791, -7.617499828338623, -7.867700099945068, -7.298999786376953, -8.04419994354248, -8.308300018310547, -7.826099872589111, -6.824100017547607, -7.530099868774414, -8.427900314331055, -8.270099639892578, -7.271100044250488, -8.131099700927734, -8.223099708557129, -8.410200119018555, -8.477999687194824, -8.502099990844727, -7.992599964141846, -7.968699932098389, -7.816400051116943, -8.48270034790039, -8.57979965209961, -7.6020002365112305, -7.955599784851074, -6.280600070953369, -7.2307000160217285, -6.662700176239014, -5.8267998695373535, -7.600100040435791, -5.84689998626709, -6.755300045013428, -6.446499824523926, -7.045899868011475, -7.841400146484375, -7.542300224304199, -7.1930999755859375, -6.323400020599365, -6.771900177001953, -5.932199954986572, -6.184299945831299, -7.267899990081787, -7.611700057983398, -6.629899978637695, -5.945499897003174, -5.749100208282471, -6.995299816131592, -5.619800090789795, -5.514999866485596, -6.416200160980225, -5.764599800109863, -5.094099998474121, -5.979100227355957, -4.717599868774414, -6.5680999755859375, -5.604300022125244, -6.2164998054504395, -5.620500087738037, -5.659800052642822, -5.1915998458862305, -6.1321001052856445, -5.599899768829346, -5.636099815368652, -5.813000202178955, -5.5854997634887695, -5.420599937438965, -5.911900043487549, -5.84060001373291, -5.860899925231934, -5.578400135040283, -5.587699890136719, -5.669000148773193, -5.95959997177124, -6.020199775695801, -5.985099792480469, -6.1315999031066895], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.854, 0.8422, 0.8406, 0.8371, 0.8335, 0.8304, 0.8297, 0.8283, 0.8275, 0.8263, 0.8263, 0.8255, 0.825, 0.8247, 0.8229, 0.8222, 0.8219, 0.8217, 0.8213, 0.8212, 0.8203, 0.8195, 0.8191, 0.8186, 0.8186, 0.8162, 0.8155, 0.8155, 0.8153, 0.8144, 0.8104, 0.7945, 0.81, 0.8124, 0.7727, 0.7983, 0.7834, 0.7776, 0.8084, 0.8041, 0.8042, 0.7826, 0.7472, 0.7224, 0.7492, 0.769, 0.773, 0.7245, 0.7507, 0.6983, 0.6631, 0.739, 0.7119, 0.6988, 0.5801, 0.6653, 0.691, 0.5471, 0.6818, 0.6611, 0.648, 0.5823, 0.6407, 0.5728, 0.6171, 0.685, 0.3674, 0.6202, 0.6354, 0.3551, 0.6287, 0.4787, 0.4622, 0.591, 0.4394, 0.4079, 0.1349, 0.3297, 0.3073, 0.0644, 0.3514, 0.4219, 0.3241, 0.263, 0.1898, -0.2916, -0.0937, 0.1487, -0.1276, 1.714, 1.7029, 1.6975, 1.6948, 1.6931, 1.6928, 1.6924, 1.6904, 1.6859, 1.684, 1.681, 1.6807, 1.6738, 1.6725, 1.6689, 1.6687, 1.6686, 1.6685, 1.6685, 1.6684, 1.6661, 1.6658, 1.6643, 1.6632, 1.6631, 1.6627, 1.6601, 1.6576, 1.6563, 1.6562, 1.6526, 1.6513, 1.6518, 1.6487, 1.6087, 1.6274, 1.6458, 1.623, 1.6223, 1.4832, 1.5887, 1.5359, 1.5584, 1.5879, 1.4889, 1.45, 1.4534, 1.5758, 1.4065, 1.4464, 1.5848, 1.1788, 1.3936, 1.5259, 1.1543, 0.8969, 1.1384, 1.3981, 1.1838, 1.2523, 0.888, 1.0129, 1.1273, 1.0487, 0.3892, 0.9981, 0.884, 0.7006, 0.7033, 1.1189, 0.8755, 0.5239, 0.2358, 0.7527, 0.7206, 0.7415, 0.4983, 0.4552, -0.2274, 0.2546, 0.8381, -0.1677, 0.6498, 0.4915, -0.2452, 0.0845, 0.1476, 0.5147, -0.825, 0.0782, 0.2127, -0.134, 0.4315, -0.042, 1.7438, 1.743, 1.7333, 1.7215, 1.7213, 1.7189, 1.7186, 1.7121, 1.712, 1.7083, 1.7073, 1.7027, 1.6999, 1.6976, 1.6956, 1.695, 1.6938, 1.6918, 1.6914, 1.6912, 1.6912, 1.6889, 1.6885, 1.6883, 1.6867, 1.6859, 1.6859, 1.685, 1.6847, 1.6839, 1.6823, 1.6811, 1.6798, 1.6758, 1.6694, 1.5853, 1.6659, 1.5273, 1.4027, 1.6276, 1.635, 1.625, 1.2976, 1.5933, 1.1384, 1.1447, 1.0491, 1.1543, 1.5792, 0.9189, 1.4597, 1.0589, 1.296, 0.9473, 0.6917, 0.5019, 1.1173, 0.513, 1.0918, 0.7449, 0.3349, 0.5515, 0.9295, 0.9218, 1.142, 0.6964, 0.9522, 0.5125, 0.931, 0.7363, 0.0499, 0.7025, 0.5532, 0.4311, 0.5212, -0.0439, 0.3417, 0.03, 0.2152, 0.2415, -0.5668, 0.4274, -0.7177, -0.071, -0.0303, -0.0153, -0.0948, 2.0219, 2.0218, 2.0194, 2.0129, 2.0114, 2.0106, 2.0082, 2.0063, 2.0049, 1.996, 1.9958, 1.9953, 1.9924, 1.9909, 1.9907, 1.986, 1.982, 1.9788, 1.9782, 1.9775, 1.9743, 1.9722, 1.9712, 1.9709, 1.9701, 1.9676, 1.9675, 1.9672, 1.9655, 1.9644, 1.9592, 1.9622, 1.9538, 1.917, 1.8564, 1.8883, 1.9182, 1.9386, 1.8931, 1.9166, 1.7237, 1.1331, 1.7012, 1.4911, 1.333, 1.3316, 1.2626, 1.3503, 0.3758, 0.7411, 0.4196, 0.7028, 1.2723, 0.4938, 0.4087, 0.3718, 0.9395, 0.8227, 0.4604, 0.6133, 1.0352, 1.0237, 0.1047, 0.3145, 0.8448, 0.2764, -0.2512, 0.2662, -0.5285, 0.6407, 0.1439, -0.4645, -0.0268, 0.353, 0.4177, -0.7937, -0.122, -0.3027, -0.2033, -0.2156, 0.1574, -1.2386, -1.2384, -0.1173, -0.489, 2.1973, 2.1965, 2.1956, 2.1793, 2.169, 2.1676, 2.1676, 2.1669, 2.1654, 2.1651, 2.16, 2.16, 2.16, 2.157, 2.1566, 2.1558, 2.1549, 2.1542, 2.1526, 2.1509, 2.1505, 2.1496, 2.1491, 2.1488, 2.147, 2.1452, 2.1448, 2.1446, 2.1438, 2.1418, 2.1326, 2.1417, 2.1189, 2.0925, 2.1304, 2.0652, 2.0979, 2.0785, 2.0759, 2.1196, 2.0585, 1.9996, 1.8386, 1.9026, 1.635, 1.6989, 1.9515, 2.0409, 1.6423, 1.3343, 1.2071, 1.7339, 0.9662, 0.8728, 1.3588, 0.9078, 0.3125, 0.9673, -0.1125, 1.4003, 0.5877, 1.0251, 0.4267, 0.3544, -0.235, 0.8614, 0.2059, 0.0314, 0.2308, -0.1429, -0.4753, 0.3404, 0.1938, 0.2287, -0.6899, -0.989, -0.9646, 0.1217, 0.2444, -0.1685, -0.5505]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 5, 4, 5, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 1, 2, 3, 4, 5, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 4, 2, 4, 5, 2, 2, 1, 4, 1, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 4, 4, 2, 3, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 1, 3, 4, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 3, 5, 1, 2, 3, 5, 3, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 4, 5, 2, 3, 5, 3, 4, 3, 4, 1, 3, 1, 3, 4, 5, 1, 1, 5, 2, 5, 2, 3, 1, 2, 3, 4, 5, 5, 2, 3, 1, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 5, 3, 4, 1, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 2, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 1, 2, 3, 4, 3, 3, 1, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 4, 2, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 3, 3, 1, 2, 1, 4, 1, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 1, 2, 5, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 5, 4, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 1, 1, 2, 3, 4, 5, 3, 1, 3, 5], \"Freq\": [0.38208438413435947, 0.10093664671341945, 0.17514121347533967, 0.19403802861346844, 0.14748733766344393, 0.9384601762523931, 0.050207972048923834, 0.9037434968806289, 0.9597710162607718, 0.9528370856533287, 0.03176123618844429, 0.8523404060147175, 0.09470448955719084, 0.5963770499526815, 0.18888810478928345, 0.04881377988936538, 0.12451051102214938, 0.041031872950481045, 0.9489761961596223, 0.011433448146501473, 0.022866896293002946, 0.011433448146501473, 0.011433448146501473, 0.030557455537196243, 0.030557455537196243, 0.061114911074392486, 0.8556087550414948, 0.9704294720719399, 0.9395731829864944, 0.16493105907846026, 0.1107933831977443, 0.43813746991835245, 0.14856385474242986, 0.13723271327902417, 0.9572829174992609, 0.9174874217552705, 0.04828881167133003, 0.10886148868843652, 0.046654923723615654, 0.6220656496482087, 0.13218895055024435, 0.09330984744723131, 0.9011446357487439, 0.3489578891845079, 0.14080756932006458, 0.3403869936606779, 0.08448454159203875, 0.08326012794577732, 0.9575563282430658, 0.8556000745162021, 0.11562163169137867, 0.023124326338275734, 0.8787939785858551, 0.019792657175357095, 0.0831291601364998, 0.011875594305214258, 0.007917062870142839, 0.8442992063823204, 0.016120271243576522, 0.10881183089414152, 0.024180406865364785, 0.006045101716341196, 0.5707202893879535, 0.1525579235094722, 0.11963175296785948, 0.09438835555262308, 0.062010954520037256, 0.5055029223265585, 0.12418929925669775, 0.11894186407683728, 0.167917925755535, 0.08308439034779075, 0.018176925321747344, 0.8906693407656199, 0.018176925321747344, 0.05453077596524203, 0.018176925321747344, 0.5873785338451443, 0.1017966781763497, 0.11115729226153129, 0.1497698253629053, 0.050313300707851005, 0.983997178731548, 0.9272390502199491, 0.04938170733066084, 0.016460569110220282, 0.016460569110220282, 0.9217918701723358, 0.016460569110220282, 0.984543958307974, 0.9649445521166319, 0.047436735731176634, 0.9012979788923561, 0.047436735731176634, 0.9165005937899505, 0.9708555368528081, 0.057819197057385543, 0.9251071529181687, 0.9436234965420751, 0.4532937461858169, 0.052810921885726246, 0.1232254844000279, 0.35647372272865213, 0.017603640628575414, 0.8801308747864952, 0.9295901191394739, 0.01019660094120081, 0.03738753678440297, 0.008497167451000674, 0.01359546792160108, 0.9688470242996979, 0.010588492068849159, 0.010588492068849159, 0.005294246034424579, 0.005294246034424579, 0.1126581755028577, 0.22306318749565823, 0.2546074766364584, 0.15321511868388646, 0.2546074766364584, 0.9609825223280579, 0.9803816608279277, 0.06373852251969873, 0.29417779624476337, 0.2745659431617792, 0.09969358650516981, 0.2680286588007844, 0.41782409067138904, 0.06162397447503468, 0.29457614172131963, 0.18487192342510406, 0.04063119196156133, 0.9531764781531449, 0.018573066093135988, 0.271842149181354, 0.5335535350391793, 0.08104610658822978, 0.09624225157352286, 0.11685719264415087, 0.480622324584814, 0.19790331012315873, 0.12439636636312834, 0.07916132404926349, 0.9644309490375372, 0.14269498470509254, 0.14982973394034715, 0.14269498470509254, 0.4922976972325693, 0.0784822415878009, 0.9094260347400502, 0.0779508029777186, 0.9137134926820241, 0.2280185936619062, 0.20615379700939462, 0.23426567841976664, 0.23582744960923174, 0.09682981374683687, 0.8171786133039344, 0.01838939214186069, 0.0333307732571225, 0.11378436387776301, 0.01838939214186069, 0.7441737661837372, 0.004085125889389226, 0.15455392948189237, 0.07285141169410785, 0.023829901021437148, 0.9181293992350517, 0.889596431330799, 0.021697473934897536, 0.04339494786979507, 0.02892996524653005, 0.01808122827908128, 0.9533053268563866, 0.023832633171409667, 0.9463886121455417, 0.37487811924254705, 0.3595485307233351, 0.12960470293515566, 0.05435035929538786, 0.0822223384212278, 0.16590128911972757, 0.20917988628139564, 0.07934409479639146, 0.45442527019751466, 0.09377029385028081, 0.4868225256135569, 0.16770594675948194, 0.16499006098200045, 0.1127092597654818, 0.06789714443703722, 0.9608750479507908, 0.04331304677481977, 0.37249220226345003, 0.1530394319376965, 0.13282667677611396, 0.3003037909720837, 0.9571112233102538, 0.8905608088021479, 0.06129936821000655, 0.9194905231500983, 0.04954067085537447, 0.04954067085537447, 0.8917320753967405, 0.7932396089446623, 0.02575453275794358, 0.053226034366416736, 0.11160297528442219, 0.015452719654766148, 0.9395137525881982, 0.05318002373140745, 0.03259387353826863, 0.09778162061480591, 0.8474407119949845, 0.8975677895117937, 0.9567972907290406, 0.9202461752474348, 0.0195797058563284, 0.03263284309388067, 0.0195797058563284, 0.013053137237552267, 0.17811529531550357, 0.2927069538401632, 0.35747615213670997, 0.05355914474522135, 0.1183283430417681, 0.11136924121818842, 0.20963621876364877, 0.43892583303638966, 0.11464480713637043, 0.12447150489091646, 0.2938415971265316, 0.19029741528194424, 0.42816918438437457, 0.044775862419281, 0.044775862419281, 0.05268267867530964, 0.07024357156707951, 0.12292625024238917, 0.7024357156707952, 0.07024357156707951, 0.9262222904122845, 0.26655758188096595, 0.21578470914173434, 0.2166309236873882, 0.14724133094377168, 0.15401104730900256, 0.28994635674730107, 0.0072486589186825275, 0.014497317837365055, 0.0072486589186825275, 0.6813739383561576, 0.04678431395775533, 0.9356862791551065, 0.6313303549917415, 0.1425140496000987, 0.09845173474789426, 0.07435515631309497, 0.05370094622612415, 0.8644876789683156, 0.019681856088595625, 0.06585851845030075, 0.028765789667947454, 0.021952839483433583, 0.9367916434718331, 0.9013770822614439, 0.06255735383593562, 0.9383603075390343, 0.03329849201331536, 0.03329849201331536, 0.9323577763728301, 0.5098640275959175, 0.05554384658167817, 0.15381372899541648, 0.18229775288345657, 0.0982698824137383, 0.75806514524062, 0.037542273859535465, 0.1126268215786064, 0.050537676349374665, 0.041874074689481865, 0.13950099141968886, 0.8370059485181331, 0.9473584607945172, 0.8934122250204148, 0.009219260564495563, 0.7744178874176274, 0.147508169031929, 0.018438521128991126, 0.04609630282247782, 0.1919373011288895, 0.12395950697907446, 0.09596865056444474, 0.03598824396166678, 0.5558184345190758, 0.1537641000379251, 0.2508782684829304, 0.024278542111251328, 0.01618569474083422, 0.5584064685587806, 0.11263309279878662, 0.8144239017758418, 0.008664084061445126, 0.043320420307225625, 0.025992252184335374, 0.9235560368022098, 0.0053620777326456115, 0.8740186704212347, 0.10187947692026662, 0.0053620777326456115, 0.016086233197936835, 0.038389129591548825, 0.038389129591548825, 0.07677825918309765, 0.8253662862182998, 0.019194564795774412, 0.9229073230329643, 0.9719205348266503, 0.21413475105439855, 0.5723237891817562, 0.06229374576127958, 0.1051206959721593, 0.046720309320959684, 0.7778111260684526, 0.0429604982421529, 0.08818207533915597, 0.05991858965352905, 0.030524564540477063, 0.02564003488780685, 0.02564003488780685, 0.9230412559610466, 0.035323920576874626, 0.035323920576874626, 0.9184219349987403, 0.032886255158478345, 0.016443127579239172, 0.016443127579239172, 0.9372582720166329, 0.9627973194578393, 0.32452871302402453, 0.27545363934722084, 0.23904310081281807, 0.08231947842560622, 0.07915334464000598, 0.0564436391217368, 0.9030982259477888, 0.29079684294500674, 0.33404355292144366, 0.15210911784815737, 0.14465278854187516, 0.07903709064659158, 0.024201528256763655, 0.10890687715543645, 0.024201528256763655, 0.12100764128381829, 0.7260458477029097, 0.9245427327181969, 0.08404933933801789, 0.1863039430142068, 0.10974067876179305, 0.53849495857531, 0.0663548290187586, 0.09953224352813789, 0.854721708012922, 0.035912676807265634, 0.05746028289162501, 0.04309521216871876, 0.007182535361453126, 0.9075588345218224, 0.016015744138620395, 0.03203148827724079, 0.021354325518160525, 0.016015744138620395, 0.06794034235910645, 0.08884506308498537, 0.22995192798466801, 0.4494514956063966, 0.16201158562556156, 0.7256100293389374, 0.03699882981169521, 0.17849967361280614, 0.03699882981169521, 0.022041856058031186, 0.9541195499901015, 0.844089429370359, 0.04437144922118024, 0.02889303670216388, 0.038180084213573696, 0.04437144922118024, 0.8308993553123564, 0.013279213441065058, 0.09105746359587467, 0.05311685376426023, 0.011382182949484334, 0.8958345401562122, 0.5807909376988917, 0.29453412161214576, 0.06552866874274905, 0.0413865276269994, 0.017934161971699742, 0.9093927967943325, 0.012414918727567678, 0.05121153975121668, 0.01707051325040556, 0.01086305388662172, 0.0398785912717908, 0.8374504167076069, 0.0797571825435816, 0.43404803845641404, 0.24617649942304082, 0.023753872751346043, 0.24185761346825063, 0.05398607443487737, 0.9270955357540929, 0.010421371970374455, 0.08337097576299564, 0.031264115911123366, 0.010421371970374455, 0.8649738735410797, 0.11503256435173738, 0.23006512870347476, 0.03834418811724579, 0.6135070098759327, 0.0746436762229215, 0.8584022765635974, 0.03732183811146075, 0.29650224370146777, 0.28775586483121796, 0.15043771656829633, 0.09970871912084757, 0.16530656064772098, 0.7499962511523229, 0.07643797409004498, 0.09636938131244917, 0.036986116495183054, 0.04027377129475488, 0.9393612124477031, 0.04606073779961001, 0.9212147559922002, 0.3693335284644488, 0.11132563018398003, 0.2838086881085156, 0.1419043440542578, 0.0936473112277257, 0.8403131724116539, 0.028010439080388465, 0.028010439080388465, 0.0840313172411654, 0.5987705726481343, 0.2578230268954018, 0.04453099224499854, 0.05777610788710067, 0.04110553130307558, 0.9724534449790941, 0.9600532634267441, 0.9647742517615718, 0.009366740308364775, 0.009366740308364775, 0.009366740308364775, 0.009366740308364775, 0.018865693952725835, 0.22638832743271003, 0.009432846976362918, 0.5659708185817751, 0.18865693952725834, 0.9497035434317614, 0.03391798369399148, 0.9494736255966794, 0.015451445935359217, 0.249798375954974, 0.6901645851127116, 0.02575240989226536, 0.018026686924585752, 0.969034496420762, 0.9714150724928077, 0.30573770511519394, 0.4731654960116096, 0.05823575335527503, 0.08007416086350316, 0.08250065058663963, 0.44127877771849955, 0.41992657879663664, 0.0355869982031048, 0.03380764829294956, 0.0711739964062096, 0.9457776636702127, 0.907379099654082, 0.09766897429438444, 0.4978735518908865, 0.042879061885339506, 0.2906247527784122, 0.06908293303749143, 0.9421206801434753, 0.052340037785748625, 0.052340037785748625, 0.8907149810296465, 0.9021240123163631, 0.9765026782002885, 0.9382436828990948, 0.1454767758238086, 0.8364914609868995, 0.9557773528114624, 0.02654937091142951, 0.02654937091142951, 0.9269061850685778, 0.9494680772999199, 0.05247079981867923, 0.9444743967362261, 0.9702824454001329, 0.03593638686667159, 0.06027877829847533, 0.90418167447713, 0.056775446937189916, 0.5677544693718991, 0.19465867521322255, 0.07096930867148739, 0.1094955048074377, 0.9721236904597585, 0.9717751433887233, 0.9843705135469926, 0.08982370107268656, 0.8533251601905223, 0.8892522912106502, 0.2417708460745176, 0.15628758264102743, 0.2616305941449244, 0.20895908839297592, 0.1312470307261667, 0.2402504601687949, 0.6090069804278754, 0.05028498003532916, 0.061459420043180085, 0.03352332002355277, 0.9533919377481164, 0.05296621876378425, 0.3181243701769069, 0.010969805868169206, 0.038394320538592215, 0.04387922347267682, 0.592369516881137, 0.9047268887369599, 0.11299194188917584, 0.19650772502465363, 0.5060073919384831, 0.09825386251232682, 0.08351578313547779, 0.9133326066710683, 0.050740700370614907, 0.14226530741586282, 0.17640898119566992, 0.42964122839590574, 0.09958571519110399, 0.1508012258608146, 0.04620526779125405, 0.924105355825081, 0.986731668389465, 0.05787638738932359, 0.014469096847330897, 0.014469096847330897, 0.028938193694661794, 0.8826149076871848, 0.04162868492388591, 0.874202383401604, 0.04162868492388591, 0.04162868492388591, 0.15890756701306408, 0.15214554288484858, 0.35500626673131336, 0.19609869971824928, 0.13862149462841758, 0.04863656216450023, 0.024318281082250114, 0.9240946811255043, 0.4477581767225781, 0.1365647910834599, 0.16271549575901606, 0.18596056658173263, 0.06712014200059413, 0.9057547241233652, 0.6513810285483456, 0.09559050733413876, 0.08876261395312884, 0.10310119005324966, 0.06145104042908921, 0.4438390301302322, 0.2683414544409822, 0.1437947878228048, 0.04415745452826289, 0.09963733329454191, 0.3516024321913237, 0.3704124388517649, 0.07813387382029416, 0.12443542867676477, 0.07524002664176474, 0.5073581592103115, 0.2255589929508106, 0.08196706109883568, 0.07418916479018704, 0.11128374718528057, 0.8027877187588933, 0.02536454087705824, 0.10272639055208586, 0.04692440062255774, 0.021559859745499503, 0.9287034729244853, 0.9038540217568717, 0.031810667656615214, 0.8270773590719955, 0.07952666914153804, 0.031810667656615214, 0.031810667656615214, 0.04707955586214121, 0.9415911172428241, 0.9020041334827412, 0.04747390176224954, 0.034777249979231865, 0.034777249979231865, 0.9042084994600285, 0.02031796637958738, 0.08127186551834951, 0.08127186551834951, 0.02031796637958738, 0.7924006888039078, 0.9480006049509128, 0.9619545028041733, 0.014146389747120194, 0.014146389747120194, 0.014204413491274558, 0.7102206745637278, 0.028408826982549117, 0.028408826982549117, 0.21306620236911836, 0.796790704035232, 0.01978784861014649, 0.07123625499652736, 0.08178977425527216, 0.030341367868891286, 0.7879395530245799, 0.037676943283919614, 0.09173516625649994, 0.0606107348480446, 0.021295663595258914, 0.8882941447584726, 0.81475779035888, 0.023760575259760375, 0.051353501367869196, 0.042155859331832926, 0.06821584510060237, 0.9590993557326054, 0.9066854081532713, 0.012307946717012732, 0.024615893434025465, 0.020513244528354554, 0.036923840151038195, 0.9307149818156899, 0.024276893042503765, 0.8496912564876318, 0.024276893042503765, 0.09710757217001506, 0.9419450982432384, 0.10275315401706438, 0.05137657700853219, 0.7792114179627382, 0.034251051339021454, 0.025688288504266094, 0.19842426904424487, 0.12358997329041538, 0.48528906943392464, 0.1088498847328429, 0.08503897244753351, 0.9455853360447235, 0.10853376014632703, 0.12589916176973937, 0.25613967394533177, 0.15194726420485785, 0.3603320836858057, 0.057873709496188266, 0.9259793519390123, 0.9384293640724575, 0.005686598087138826, 0.07961237321994356, 0.02843299043569413, 0.011373196174277652, 0.8757361054193792, 0.9398739241932671, 0.01693795292340298, 0.09598173323261688, 0.022583937231203974, 0.01693795292340298, 0.85254363047795, 0.15678405601204573, 0.4028479216976175, 0.2634843163535769, 0.07185935900552096, 0.10452270400803049, 0.9472836739665982, 0.2877765957660441, 0.3529335608451484, 0.1891361902990667, 0.04886772380932824, 0.1221693095233206, 0.5837558316871253, 0.19023171557897564, 0.09880692092758735, 0.0687105599553912, 0.05905701020959244, 0.44494666747408546, 0.06909760012538739, 0.15494613361450507, 0.26801493381968444, 0.06281600011398854, 0.9148966792497413, 0.050311285014544564, 0.9559144152763467, 0.02863371333132952, 0.5376775058882988, 0.23225123035411724, 0.022270665924367404, 0.17816532739493923, 0.5458193742122082, 0.03383441734882694, 0.33898255872126615, 0.037026343513810615, 0.04341019584377796, 0.7518756348699389, 0.013514104548315895, 0.15848358970297732, 0.0565135281111392, 0.020271156822473844, 0.05352469723393031, 0.7386408218282383, 0.09634445502107455, 0.09634445502107455, 0.021409878893572123, 0.14931398734205084, 0.23890237974728132, 0.07167071392418439, 0.10153351139259456, 0.43599684303878844, 0.04380909901008523, 0.9199910792117899, 0.935840470573363, 0.03466075816938381, 0.08192414520589605, 0.7447649564172368, 0.06702884607755132, 0.04468589738503421, 0.05213354694920658, 0.8783680813356971, 0.05019246179061126, 0.02509623089530563, 0.05019246179061126, 0.00931845059659867, 0.01863690119319734, 0.05591070357959202, 0.01863690119319734, 0.9132081584666697, 0.03478974275018196, 0.03478974275018196, 0.9045333115047309, 0.9556462235760778, 0.3034896837816692, 0.20209496105369731, 0.21042877388065392, 0.19237217942224796, 0.09097745669427612, 0.9321709677930854, 0.04499932302196325, 0.21899670537355448, 0.26099607352738685, 0.06599900709887943, 0.41099381693393106, 0.9608439517189022, 0.9093863090774676, 0.9437584413545954, 0.6848319893797432, 0.02090151493618606, 0.019672014057586878, 0.017213012300388516, 0.2581951845058278, 0.6063215037499077, 0.13917270532867937, 0.08292459856879707, 0.0752732016933719, 0.0965730362384744, 0.9383575611186924, 0.0407981548312475, 0.9436547007840842, 0.023590333239706086, 0.8964326631088313, 0.07077099971911825, 0.013469529068303635, 0.02693905813660727, 0.02693905813660727, 0.040408587204910904, 0.9024584475763435, 0.045185123841015314, 0.49703636225116843, 0.022592561920507657, 0.3614809907281225, 0.0722961981456245, 0.1878050113081612, 0.04173444695736916, 0.7512200452326449, 0.057042631563062704, 0.7985968418828778, 0.0380284210420418, 0.057042631563062704, 0.0380284210420418, 0.6397435705129032, 0.08559949182919128, 0.10362043747744208, 0.09911520106537938, 0.07208378259300319, 0.06332359297515858, 0.7685181511076064, 0.07195862838086202, 0.03741848675804825, 0.05756690270468961, 0.9388308545577979, 0.9707481022518206, 0.9518678189860205, 0.021152618199689343, 0.021152618199689343, 0.021152618199689343, 0.9251006602305738, 0.9162058822896709, 0.9574615616002737, 0.019947115866672367, 0.019947115866672367, 0.9518474692351031, 0.035253609971670485, 0.4356501948628197, 0.35177255420160886, 0.07103922627429084, 0.06590386051952282, 0.07531869773659751, 0.019633777201391513, 0.922787528465401, 0.019633777201391513, 0.019633777201391513, 0.9373247108403675, 0.9421103317385248, 0.04958475430202762, 0.00827762242214776, 0.7449860179932983, 0.02483286726644328, 0.1241643363322164, 0.09105384664362536, 0.9248638625741968, 0.6776460070398894, 0.031231273636350747, 0.16705099852001562, 0.08788335139531256, 0.0355891257716555, 0.010109369262845646, 0.7076558483991952, 0.1314218004169934, 0.08087495410276517, 0.07076558483991952, 0.22782654169126754, 0.12036119183689606, 0.24287169067087955, 0.12465980583107092, 0.2837085236155407, 0.9157172698077596, 0.40514859792594754, 0.20074930527862267, 0.14508699790591364, 0.11314960842976914, 0.1359620294841581, 0.06905368079928678, 0.250598035158702, 0.1770892781788161, 0.3965017800733241, 0.10692182833437952, 0.021568847743249762, 0.3774548355068708, 0.03235327161487464, 0.48529907422311963, 0.0808831790371866, 0.16798551836440143, 0.0373301151920892, 0.7279372462457394, 0.0373301151920892, 0.0186650575960446, 0.09343848525390173, 0.8876656099120666, 0.03697971618966414, 0.9244929047416036, 0.03697971618966414, 0.9430754100617011, 0.06246859292174186, 0.25299780133305455, 0.4310332911600188, 0.09682631902869988, 0.15617148230435465, 0.9154668757889979, 0.1368489466649129, 0.12638915456313612, 0.42536487880558915, 0.1752015177047611, 0.13597729732309816, 0.8129162346445103, 0.020250582357692427, 0.040501164715384855, 0.10848526263049516, 0.018804112189285828, 0.014767323649522598, 0.305191355423467, 0.2264322959593465, 0.03445708851555273, 0.41840750340314026, 0.918060933016449, 0.008785272086281808, 0.03514108834512723, 0.021963180215704523, 0.017570544172563617, 0.8665141611865672, 0.016437938017089353, 0.06340347520877321, 0.029353460744802416, 0.02465690702563403, 0.9287925713050779, 0.008443568830046162, 0.03377427532018465, 0.008443568830046162, 0.016887137660092325, 0.051133424047671794, 0.9204016328580923, 0.9388474481670458, 0.9242897348184005, 0.4804217696415381, 0.14769537832408428, 0.23746561756567452, 0.0801618038487595, 0.054081764925361715, 0.07179372034513715, 0.8974215043142144, 0.16032054783819155, 0.5547599909321549, 0.10688036522546104, 0.030537247207274583, 0.14759669483516047, 0.9435248133790743, 0.9310047426878787, 0.9712200151499922, 0.9411602303794115, 0.9385740735060961, 0.8615191728853, 0.9363408328385355, 0.027539436259956928, 0.8387317844981893, 0.029055373596934966, 0.06392182191325692, 0.0561737222874076, 0.013559174345236317, 0.9469020410424758, 0.8327928810339381, 0.02299121450707191, 0.0945194374179623, 0.04598242901414382, 0.005109158779349313, 0.03218319292625652, 0.09654957877876957, 0.03218319292625652, 0.8367630160826697, 0.3748684904143048, 0.42806351826942324, 0.06633732885461822, 0.07822798213987997, 0.053195027855118385, 0.9498007819198854, 0.4172126049163432, 0.0975094593865783, 0.18702634013491248, 0.19342040304550778, 0.1039035222971736, 0.12297026514219657, 0.37790861970528705, 0.08397969326784156, 0.29692820119701124, 0.11697171562306503, 0.12741205999854804, 0.3672465258781679, 0.10492757882233368, 0.1184182675280623, 0.283304462820301, 0.41134015716160816, 0.1518794426442861, 0.07593972132214305, 0.32590797067419724, 0.03480570560598223, 0.932708572878691, 0.11866336673857453, 0.8306435671700217, 0.029665841684643632, 0.029665841684643632, 0.015652266340056495, 0.20347946242073445, 0.06260906536022598, 0.7200042516425987, 0.015652266340056495, 0.8982482845558686, 0.8863377036423503, 0.0068311191032165725, 0.05635673260153672, 0.03415559551608286, 0.01537001798223729, 0.5744401365728468, 0.030167534524613397, 0.26019498527479057, 0.08924562296864796, 0.04650828239211232, 0.9431989839156187, 0.016842838998493193, 0.016842838998493193, 0.008421419499246597, 0.014035699165410993, 0.8989137572703525, 0.9711525696968086, 0.026652437056453666, 0.026652437056453666, 0.9328352969758783, 0.9718057895895595, 0.930852400170276, 0.7809881847792174, 0.021148616222261205, 0.07704138766680868, 0.09365815755572819, 0.02870169344449735, 0.8871575157886027, 0.02033069307015548, 0.042509630964870544, 0.0332684068420726, 0.014785958596476712, 0.05582101705740069, 0.7017499287216087, 0.10366760310660128, 0.07176987907380089, 0.0637954480656008, 0.22866950531606894, 0.019055792109672412, 0.5192703349885732, 0.07622316843868965, 0.1524463368773793, 0.17409249987044556, 0.5440390620951424, 0.1387299608342613, 0.10064722648760134, 0.04080292965713568, 0.21632838136485225, 0.5328087911393583, 0.1442189209099015, 0.056085135909406135, 0.048072973636633834, 0.31356165997272095, 0.22099191030879678, 0.2806479712033257, 0.09932881075049642, 0.08551681635619662, 0.4077562875010829, 0.1036668527545126, 0.2856597720346569, 0.07256679692815882, 0.13015949290288803, 0.9660205314204057, 0.9443658668660426, 0.017170288488473504, 0.017170288488473504, 0.017170288488473504, 0.017170288488473504, 0.08804600680270742, 0.13099527841378422, 0.5304235043967984, 0.09985705649575354, 0.15139618242904568, 0.09863482236872737, 0.8482594723710554, 0.039453928947490946, 0.18628274127011962, 0.28517357922833125, 0.2955226204100046, 0.1402870026849049, 0.09199147717042944, 0.9214773896426032, 0.9167297180730176, 0.666827757917608, 0.08780999188419986, 0.0924315704044209, 0.10431562945641788, 0.048856687213765335, 0.044918844976520385, 0.9432957445069281, 0.05677932735532442, 0.03785288490354961, 0.018926442451774807, 0.018926442451774807, 0.8516899103298663, 0.036715509285387915, 0.9546032414200858, 0.9512537489834382, 0.06377090202330318, 0.8927926283262445, 0.9467714676435788, 0.07178181544025206, 0.9331636007232768, 0.43469516385463686, 0.20909387628450887, 0.0583261865425209, 0.2575156160556583, 0.04071828117119383, 0.17541661651487064, 0.17541661651487064, 0.09619620905654197, 0.4809810452827098, 0.06790320639285315, 0.043831480962366776, 0.9204611002097023, 0.17249588970785565, 0.060880902249831406, 0.6223381118871655, 0.07440999163868282, 0.07102771929146998, 0.2860967597965943, 0.10482934710104219, 0.4892036198048636, 0.0698862314006948, 0.050230728819249386, 0.3699832230717371, 0.11321890979244413, 0.11928420853132507, 0.20217662462936453, 0.19408955964418995, 0.2598800439604802, 0.18175659516254444, 0.34278656105216715, 0.09885007807085751, 0.11638799514794512, 0.4214443891542519, 0.20265198286991687, 0.14705719110914323, 0.16678437528232096, 0.06187162308860294, 0.3510703985333474, 0.14771063734769022, 0.28374182895160954, 0.08519125130750504, 0.13259606050281028, 0.9223908256866578, 0.043923372651745604, 0.043923372651745604, 0.9291978028013897, 0.04039990446962564, 0.15188771310599863, 0.13923040368049877, 0.5316069958709952, 0.1329017489677488, 0.044300582989249604, 0.18152711836591456, 0.42392560576471067, 0.17609217470226443, 0.079350177489292, 0.13804756905671348, 0.2186084326612094, 0.4224238134882017, 0.14628684591614766, 0.11834441467373744, 0.09368932828337546, 0.9600159770596065, 0.0290913932442305, 0.0290913932442305, 0.9748362284625872, 0.9931061836971149, 0.913989277143234, 0.016034899599004105, 0.03206979919800821, 0.02004362449875513, 0.02004362449875513, 0.8612489476298404, 0.020572277185571173, 0.020572277185571173, 0.946324750536274], \"Term\": [\"$\", \"$\", \"$\", \"$\", \"$\", \"a.m.\", \"acrylic\", \"acrylic\", \"adds\", \"ale\", \"ale\", \"alex\", \"alex\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"ambience\", \"ambience\", \"ambience\", \"ambience\", \"ambience\", \"answers\", \"answers\", \"answers\", \"answers\", \"appetite\", \"arrogant\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"attached\", \"audience\", \"audience\", \"awful\", \"awful\", \"awful\", \"awful\", \"awful\", \"baba\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"barbeque\", \"barber\", \"barber\", \"barber\", \"bbq\", \"bbq\", \"bbq\", \"bbq\", \"bbq\", \"beef\", \"beef\", \"beef\", \"beef\", \"beef\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bike\", \"bike\", \"bike\", \"bike\", \"bike\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bleu\", \"blind\", \"boba\", \"boba\", \"boba\", \"boba\", \"boba\", \"bouchon\", \"bouncers\", \"bourbon\", \"bourbon\", \"bourbon\", \"brakes\", \"brewery\", \"brows\", \"brows\", \"brulee\", \"buffet\", \"buffet\", \"buffet\", \"buffet\", \"buffet\", \"bumper\", \"burger\", \"burger\", \"burger\", \"burger\", \"burger\", \"burgers\", \"burgers\", \"burgers\", \"burgers\", \"burgers\", \"business\", \"business\", \"business\", \"business\", \"business\", \"butternut\", \"cajun\", \"called\", \"called\", \"called\", \"called\", \"called\", \"came\", \"came\", \"came\", \"came\", \"came\", \"capacity\", \"car\", \"car\", \"car\", \"car\", \"car\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carolina\", \"casino\", \"casino\", \"casino\", \"casino\", \"casino\", \"cats\", \"cats\", \"cesar\", \"check\", \"check\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chilled\", \"chips\", \"chips\", \"chips\", \"chips\", \"chips\", \"chorizo\", \"chorizo\", \"circle\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"club\", \"club\", \"club\", \"club\", \"club\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comme\", \"company\", \"company\", \"company\", \"company\", \"company\", \"computers\", \"contractor\", \"convention\", \"convention\", \"cousin\", \"cousin\", \"cousin\", \"cream\", \"cream\", \"cream\", \"cream\", \"cream\", \"creme\", \"creme\", \"cupcakes\", \"cupcakes\", \"cupcakes\", \"curls\", \"curly\", \"curry\", \"curry\", \"curry\", \"curry\", \"curry\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customers\", \"customers\", \"customers\", \"customers\", \"customers\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"dance\", \"dance\", \"dance\", \"dance\", \"dance\", \"dans\", \"day\", \"day\", \"day\", \"day\", \"day\", \"de\", \"de\", \"de\", \"de\", \"de\", \"death\", \"death\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dente\", \"dentistry\", \"dentists\", \"dentists\", \"des\", \"des\", \"des\", \"different\", \"different\", \"different\", \"different\", \"different\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"direct\", \"direct\", \"directions\", \"dissatisfied\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dogs\", \"dogs\", \"dogs\", \"dogs\", \"dogs\", \"donuts\", \"donuts\", \"donuts\", \"donuts\", \"donuts\", \"doughnuts\", \"dr.\", \"dr.\", \"dr.\", \"dr.\", \"dr.\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"ears\", \"easter\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"en\", \"en\", \"en\", \"est\", \"est\", \"est\", \"et\", \"et\", \"et\", \"et\", \"ethiopian\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"eyebrow\", \"eyebrow\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feet\", \"feet\", \"feet\", \"feet\", \"feet\", \"fi\", \"fi\", \"finally\", \"finally\", \"finally\", \"finally\", \"finally\", \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"flavorful\", \"flavorful\", \"flavorful\", \"flavorful\", \"flavorful\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"food\", \"food\", \"food\", \"food\", \"food\", \"freezer\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fried\", \"fried\", \"fried\", \"fried\", \"fried\", \"friendlier\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"fries\", \"fries\", \"fries\", \"fries\", \"fries\", \"frosting\", \"frosting\", \"frosting\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"gabi\", \"gel\", \"gel\", \"gel\", \"gel\", \"gel\", \"gift\", \"gift\", \"gift\", \"gift\", \"gifts\", \"gifts\", \"gifts\", \"going\", \"going\", \"going\", \"going\", \"going\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gooey\", \"gordon\", \"gordon\", \"got\", \"got\", \"got\", \"got\", \"got\", \"grateful\", \"grateful\", \"grateful\", \"grateful\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greatest\", \"grubhub\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"gym\", \"gym\", \"gym\", \"gym\", \"gym\", \"gyros\", \"gyros\", \"hahaha\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hakka\", \"heartbeat\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"hoagie\", \"horribly\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"houses\", \"houses\", \"houses\", \"howard\", \"humor\", \"ihop\", \"ikea\", \"involved\", \"involved\", \"jalape\\u00f1o\", \"jalape\\u00f1o\", \"jalape\\u00f1o\", \"jalape\\u00f1os\", \"jambalaya\", \"je\", \"je\", \"jennifer\", \"jennifer\", \"jeremy\", \"jeremy\", \"job\", \"job\", \"job\", \"job\", \"job\", \"johnny\", \"josh\", \"keg\", \"kevin\", \"kevin\", \"kia\", \"know\", \"know\", \"know\", \"know\", \"know\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"l\", \"l\", \"la\", \"la\", \"la\", \"la\", \"la\", \"label\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lane\", \"lane\", \"later\", \"later\", \"later\", \"later\", \"later\", \"laughed\", \"laughed\", \"layout\", \"le\", \"le\", \"le\", \"le\", \"le\", \"lead\", \"lead\", \"lead\", \"lead\", \"left\", \"left\", \"left\", \"left\", \"left\", \"les\", \"les\", \"les\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lil\", \"little\", \"little\", \"little\", \"little\", \"little\", \"location\", \"location\", \"location\", \"location\", \"location\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"macy\", \"mahi\", \"maintenance\", \"maintenance\", \"maintenance\", \"maintenance\", \"maintenance\", \"mais\", \"mais\", \"male\", \"male\", \"mandalay\", \"mandalay\", \"mandalay\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicures\", \"margarita\", \"margarita\", \"margarita\", \"massage\", \"massage\", \"massage\", \"massage\", \"massage\", \"meal\", \"meal\", \"meal\", \"meal\", \"meal\", \"meat\", \"meat\", \"meat\", \"meat\", \"meat\", \"medicine\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mercedes\", \"mexican\", \"mexican\", \"mexican\", \"mexican\", \"mexican\", \"michelle\", \"mike\", \"mike\", \"mike\", \"mike\", \"milkshakes\", \"mins\", \"mins\", \"mins\", \"mins\", \"mins\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"mold\", \"money\", \"money\", \"money\", \"money\", \"money\", \"msg\", \"msg\", \"mule\", \"nail\", \"nail\", \"nail\", \"nail\", \"nail\", \"nailed\", \"nails\", \"nails\", \"nails\", \"nails\", \"nails\", \"needed\", \"needed\", \"needed\", \"needed\", \"needed\", \"neighbor\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nite\", \"oasis\", \"oasis\", \"office\", \"office\", \"office\", \"office\", \"office\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"park\", \"park\", \"park\", \"park\", \"park\", \"pas\", \"pas\", \"pastor\", \"pastor\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patients\", \"patients\", \"patients\", \"patients\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicures\", \"pedicures\", \"pedicures\", \"pee\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peter\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"pico\", \"pinch\", \"pistachio\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plumber\", \"plumber\", \"plumbers\", \"plumbing\", \"plumbing\", \"plumbing\", \"polish\", \"polish\", \"polish\", \"polish\", \"polish\", \"pool\", \"pool\", \"pool\", \"pool\", \"pool\", \"pour\", \"pour\", \"pour\", \"pressure\", \"pressure\", \"pressure\", \"pressure\", \"pressure\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professionally\", \"promotion\", \"queso\", \"queso\", \"queso\", \"queso\", \"queue\", \"ramsay\", \"ravioli\", \"ravioli\", \"ravioli\", \"reach\", \"reach\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"referred\", \"referred\", \"referred\", \"referred\", \"refrigerator\", \"rep\", \"rep\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"repeated\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"results\", \"results\", \"results\", \"results\", \"results\", \"review\", \"review\", \"review\", \"review\", \"review\", \"rick\", \"right\", \"right\", \"right\", \"right\", \"right\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rooms\", \"rooms\", \"rooms\", \"rooms\", \"rooms\", \"root\", \"root\", \"root\", \"root\", \"root\", \"roti\", \"roti\", \"routine\", \"routine\", \"routine\", \"rubber\", \"rude\", \"rude\", \"rude\", \"rude\", \"rude\", \"rugs\", \"said\", \"said\", \"said\", \"said\", \"said\", \"salad\", \"salad\", \"salad\", \"salad\", \"salad\", \"salon\", \"salon\", \"salon\", \"salon\", \"salon\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauces\", \"sauces\", \"sauces\", \"sauces\", \"sauces\", \"screens\", \"screens\", \"screwed\", \"scrumptious\", \"service\", \"service\", \"service\", \"service\", \"service\", \"sessions\", \"sessions\", \"shop\", \"shop\", \"shop\", \"shop\", \"shop\", \"sisters\", \"skill\", \"skinny\", \"smog\", \"smokey\", \"solved\", \"soo\", \"soo\", \"soup\", \"soup\", \"soup\", \"soup\", \"soup\", \"spell\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spray\", \"spray\", \"spray\", \"spray\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"staffs\", \"stars\", \"stars\", \"stars\", \"stars\", \"stars\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"store\", \"store\", \"store\", \"store\", \"store\", \"strip\", \"strip\", \"strip\", \"strip\", \"strip\", \"stunning\", \"stylist\", \"stylist\", \"stylist\", \"stylist\", \"suite\", \"suite\", \"suite\", \"suite\", \"suite\", \"sur\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"table\", \"table\", \"table\", \"table\", \"table\", \"tacos\", \"tacos\", \"tacos\", \"tacos\", \"tacos\", \"tai\", \"tamale\", \"tan\", \"tan\", \"tan\", \"tart\", \"tartar\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"team\", \"team\", \"team\", \"team\", \"team\", \"terrible\", \"terrible\", \"terrible\", \"terrible\", \"terrible\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thanks\", \"thanks\", \"thanks\", \"thanks\", \"thanks\", \"time\", \"time\", \"time\", \"time\", \"time\", \"times\", \"times\", \"times\", \"times\", \"times\", \"tint\", \"toasted\", \"toasted\", \"toasted\", \"toasted\", \"toasted\", \"told\", \"told\", \"told\", \"told\", \"told\", \"tony\", \"tony\", \"tony\", \"took\", \"took\", \"took\", \"took\", \"took\", \"tricks\", \"trusted\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"un\", \"un\", \"un\", \"un\", \"un\", \"une\", \"une\", \"unorganized\", \"upcoming\", \"upcoming\", \"updating\", \"values\", \"values\", \"vegas\", \"vegas\", \"vegas\", \"vegas\", \"vegas\", \"view\", \"view\", \"view\", \"view\", \"view\", \"vous\", \"vous\", \"waited\", \"waited\", \"waited\", \"waited\", \"waited\", \"waiting\", \"waiting\", \"waiting\", \"waiting\", \"waiting\", \"want\", \"want\", \"want\", \"want\", \"want\", \"wanted\", \"wanted\", \"wanted\", \"wanted\", \"wanted\", \"way\", \"way\", \"way\", \"way\", \"way\", \"went\", \"went\", \"went\", \"went\", \"went\", \"wheels\", \"wheels\", \"wheels\", \"wi\", \"wi\", \"window\", \"window\", \"window\", \"window\", \"window\", \"work\", \"work\", \"work\", \"work\", \"work\", \"years\", \"years\", \"years\", \"years\", \"years\", \"yellowtail\", \"yellowtail\", \"yellowtail\", \"yuck\", \"yuk\", \"yummy\", \"yummy\", \"yummy\", \"yummy\", \"yummy\", \"zen\", \"\\u00e0\", \"\\u00e0\", \"\\u00e0\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 1, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el629411403033912158089221884046\", ldavis_el629411403033912158089221884046_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el629411403033912158089221884046\", ldavis_el629411403033912158089221884046_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el629411403033912158089221884046\", ldavis_el629411403033912158089221884046_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.130373  0.009338       1        1  41.983994\n",
       "3      0.073905  0.072278       2        1  17.462666\n",
       "0      0.000183 -0.019588       3        1  16.987884\n",
       "2     -0.008876  0.001065       4        1  12.764766\n",
       "4      0.065161 -0.063093       5        1  10.800690, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
       "35      time  3402.000000  3402.000000  Default  30.0000  30.0000\n",
       "145     food  5081.000000  5081.000000  Default  29.0000  29.0000\n",
       "212    great  4378.000000  4378.000000  Default  28.0000  28.0000\n",
       "398    pizza   813.000000   813.000000  Default  27.0000  27.0000\n",
       "0          $  2169.000000  2169.000000  Default  26.0000  26.0000\n",
       "...      ...          ...          ...      ...      ...      ...\n",
       "212    great   180.254826  4378.972715   Topic5  -5.6690  -0.9646\n",
       "1086     new   134.795917  1105.023844   Topic5  -5.9596   0.1217\n",
       "541     work   126.870068   919.972737   Topic5  -6.0202   0.2444\n",
       "129   people   131.404327  1439.917148   Topic5  -5.9851  -0.1685\n",
       "120     best   113.496295  1822.258678   Topic5  -6.1316  -0.5505\n",
       "\n",
       "[466 rows x 6 columns], token_table=       Topic      Freq   Term\n",
       "term                         \n",
       "0          1  0.382084      $\n",
       "0          2  0.100937      $\n",
       "0          3  0.175141      $\n",
       "0          4  0.194038      $\n",
       "0          5  0.147487      $\n",
       "...      ...       ...    ...\n",
       "2611       5  0.020044  yummy\n",
       "12099      3  0.861249    zen\n",
       "4127       1  0.020572      à\n",
       "4127       3  0.020572      à\n",
       "4127       5  0.946325      à\n",
       "\n",
       "[1183 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 4, 1, 3, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Use pyLDAvis (or a ploting tool of your choice) to visualize your results \n",
    "\n",
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f44a26c754500ff0bf585296075bf754",
     "grade": false,
     "grade_id": "cell-bf9e63d9645bba84",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "LDA divided documents into 5 major topics based on the reviews customers have given to the place:\n",
    "- first largest group is the one with 5 star reviews\n",
    "- second - 4 star reviews\n",
    "- third and forth are mostly identical - these are reviews with 3 or 2 stars, they are sharing a lot of semantic meaning\n",
    "- last smallest group is the one with one star reviews.\n",
    "By setting alpha to a larger number we can see words, that are common for some topic, but that still appear a lot in\n",
    "the corpus, when alpha is low very specific words pop out, that may reflect peculiarities of a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the plot we can see that topics are overall evenly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}